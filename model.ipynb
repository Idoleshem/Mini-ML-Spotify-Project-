{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import ipywidgets as widgets # interactive widgets\n",
    "from ipywidgets import Box\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version = 1 # no genre and time signature values\n",
    "#version = 2 # with new variables \n",
    "# version = 3 # data standartization \n",
    "version = 4 # Feature Selection\n",
    "#version = 5 # Cross Validation GridSearchCV\n",
    "#version = 6 # Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading and descriptive statistics\n",
    "df = pd.read_csv('SpotifyFeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update column values\n",
    "df[\"genre\"].replace({\"Children's Music\": \"Children’s Music\"}, inplace=True)\n",
    "# general category\n",
    "df[\"genre\"].replace({\"Soundtrack\": \"General\",\"Movie\":\"General\",\"Anime\":\"General\",\"Children’s Music\":\"General\",\"Comedy\":\"General\"}, inplace=True)\n",
    "# dance\n",
    "df[\"genre\"].replace({\"Hip-Hop\": \"Dance\",\"R&B\":\"dance\",\"Dance\":\"Dance\",\"Rap\":\"Dance\",\"Pop\":\"Dance\"}, inplace=True)\n",
    "# folk\n",
    "df[\"genre\"].replace({\"Folk\": \"Folk\",\"Soul\":\"Folk\",\"Blues\":\"Folk\",\"Country\":\"Folk\"}, inplace=True)\n",
    "# Reggae\n",
    "df[\"genre\"].replace({\"Reggaeton\": \"Reggae\",\"Ska\":\"Reggae\",\"Reggae\":\"Reggae\",\"World\":\"Reggae\"}, inplace=True)\n",
    "# Alternative\n",
    "df[\"genre\"].replace({\"Indie\": \"Alternative\",\"Rock\":\"Alternative\",\"Alternative\":\"Alternative\",\"Electronic\":\"Alternative\",\"Jazz\":\"Alternative\"}, inplace=True)\n",
    "# Reggae\n",
    "df[\"genre\"].replace({\"Classical\": \"Classical\",\"Opera\":\"Classical\",\"A Capella\":\"Classical\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for version +2\n",
    "# create dummy variables\n",
    "genre_df=pd.get_dummies(df[\"genre\"]) \n",
    "df = pd.concat([df,genre_df],axis=1) \n",
    "\n",
    "# create dummy variables - time_signature\n",
    "time_signature_df=pd.get_dummies(df[\"time_signature\"]) \n",
    "df = pd.concat([df,time_signature_df],axis=1) \n",
    "\n",
    "# remove old variables\n",
    "df.drop(['genre','time_signature','0/4','1/4'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all versions\n",
    "# Data cleaning and arrangement the data\n",
    "df['mode'] = np.where(df['mode']=='Major', 1, 0) #change songs' mode (minor/major) to numerical\n",
    "\n",
    "# change songs duration from milliseconds to seconds\n",
    "df['duration_ms'] = df['duration_ms'] / 1000\n",
    "df.rename(columns={'duration_ms': 'duration_s'}, inplace=True) # update column label\n",
    "\n",
    "# drop variables:\n",
    "df.drop_duplicates(subset=['track_id'], keep='first',inplace=True)\n",
    "if version==1:\n",
    "    df.drop(['artist_name','track_name','track_id','key','genre','time_signature'],axis=1, inplace=True)\n",
    "\n",
    "elif version>=2:\n",
    "    df.drop(['artist_name','track_name','track_id','key'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# versions +3\n",
    "# data standardtization\n",
    "# scale the dataset and make computations more efficient\n",
    "features = [\"duration_s\",\"loudness\",\"tempo\",\"popularity\"]\n",
    "for feature in features:\n",
    "    mean = df[feature].mean()\n",
    "    std = df[feature].std()\n",
    "    df[feature] = (df[feature]-mean)/std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection - version +4\n",
    "df.drop(['duration_s','mode','tempo','valence','5/4','Reggae'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All versions\n",
    "X= df.loc[:,df.columns !=\"popularity\"]\n",
    "y = df[\"popularity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualzation\n",
    "#sample = df.sample(1000)\n",
    "#sns.kdeplot(x = sample[\"acousticness\"])\n",
    "#sns.scatterplot(x=sample[\"acousticness\"], y=sample[\"popularity\"])\n",
    "#sns.pairplot(sample[[\"acousticness\",\"danceability\"]])\n",
    "#correlation_mat = df.corr()\n",
    "#print(correlation_mat)\n",
    "#sns.heatmap(correlation_mat)\n",
    "#sns.scatterplot(sample[\"loudness\"], sample[\"acousticness\"], hue=sample[\"popularity\"])\n",
    "#sns.scatterplot(sample[\"acousticness\"], sample[\"danceability\"], size=sample[\"popularity\"])\n",
    "#g = sns.PairGrid(sample[[ \"acousticness\",\"popularity\",\"genre\"]], hue=\"genre\")\n",
    "#g.map_diag(sns.histplot)\n",
    "#g.map_offdiag(sns.scatterplot)\n",
    "#g.add_legend();\n",
    "\n",
    "#df sample = diamonds.sample(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 3\n",
    "correlation_mat = df.corr()\n",
    "print(correlation_mat)\n",
    "#sns.heatmap(correlation_mat,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 4\n",
    "sample = df.sample(500)\n",
    "#g = sns.pairplot(sample[[\"loudness\", \"acousticness\", \"popularity\"]])\n",
    "#sns.pairplot(sample[[\"danceability\",\"loudness\", \"acousticness\", \"popularity\"]],diag_kind=\"kde\")\n",
    "sns.pairplot(sample[[\"danceability\",\"loudness\", \"acousticness\", \"popularity\",\"genre\"]], hue=\"genre\")\n",
    "\"\"\"\n",
    "sns.pairplot(sample[[\"danceability\",\"loudness\", \"acousticness\", \"popularity\"]],diag_kind=\"kde\")\n",
    "\n",
    "acousticness = [0,1]\n",
    "danceability = [0,1]\n",
    "duration_s = [0,600]\n",
    "energy = [0,1]\n",
    "instrumentalness = [0,1]\n",
    "liveness = [0,1]\n",
    "loudness= [ -60,0]\n",
    "speechiness = [0,1]\n",
    "tempo = [0,250]\n",
    "valence = [0,1]\n",
    "mode = [0,1]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 5 \n",
    "print(cv_results)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_test_score\"])\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_train_score\"])\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('r-squared')\n",
    "plt.title(\"Optimal Number of Features\")\n",
    "plt.legend(['test score', 'train score'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a linear regression object\n",
    "model_regression = linear_model.LinearRegression()\n",
    "\n",
    "# create a random forest regression object\n",
    "model_random_forest = RandomForestRegressor()\n",
    "\n",
    "# create a random forest regression object\n",
    "model_decision_tree = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE Track\n",
    "regression_rmse = []\n",
    "decision_tree_rmse = []\n",
    "random_forest_rmse = []\n",
    "Phase = ['baseline','feature engineering','data standartization','feature selection','cross validation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the data to training and testing\n",
    "X_train, X_test, y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "# save as np.array\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train) \n",
    "y_test = np.array(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 10, shuffle = True)\n",
    "hyper_params = [{'n_features_to_select': list(range(0,X.shape[1]))}] # specify range of hyperparameters\n",
    "model_regression.fit(X_train,y_train)\n",
    "rfe = RFE(model_regression) \n",
    "model_cv = GridSearchCV(estimator = rfe, \n",
    "                    param_grid = hyper_params, \n",
    "                    scoring= 'r2', \n",
    "                    cv = folds, \n",
    "                    verbose = 1,\n",
    "                    return_train_score=True)    \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, y_train)\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_) \n",
    "y_pred = model_cv.predict(X_test)\n",
    "#model_regression.coef\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test,y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The models\n",
    "model_regression.fit(X_train,y_train)\n",
    "model_random_forest.fit(X_train,y_train)\n",
    "model_decision_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random forest regression object\n",
    "model_random_forest = RandomForestRegressor(n_estimators = 200)\n",
    "\n",
    "model_random_forest.fit(X_train,y_train)\n",
    "# estimate the R² score on train data\n",
    "print(\"Train data - the R^2 is\",model_random_forest.score(X_train,y_train))\n",
    "# estimate the R² score on test data\n",
    "print(\"Test data - the R^2 is\",model_random_forest.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = [{'n_features_to_select': list(range(0, 18))}] # specify range of hyperparameters\n",
    "model_regression.fit(X_train,y_train)\n",
    "rfe = RFE(model_regression) \n",
    "model_cv = GridSearchCV(estimator = rfe, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'r2', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " y_pred_decision_tree= model_cv.predict(X_test)\n",
    "#model_regression.coef\n",
    "mse1 = mean_squared_error(y_test,y_pred_decision_tree)\n",
    "# we want smaller rmse\n",
    "rmse1 = np.sqrt(mse1)\n",
    "print(rmse1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the R² score on train data\n",
    "print(\"Train data - the R^2 is\",model_regression.score(X_train,y_train))\n",
    "# estimate the R² score on test data\n",
    "print(\"Test data - the R^2 is\",model_regression.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the R² score on train data\n",
    "print(\"Train data - the R^2 is\",model_random_forest.score(X_train,y_train))\n",
    "# estimate the R² score on test data\n",
    "print(\"Test data - the R^2 is\",model_random_forest.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the R² score on train data\n",
    "print(\"Train data - the R^2 is\",model_decision_tree.score(X_train,y_train))\n",
    "# estimate the R² score on test data\n",
    "print(\"Test data - the R^2 is\",model_decision_tree.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg = model_regression.predict(X_test)\n",
    "y_pred_random_forset = model_random_forest.predict(X_test)\n",
    "y_pred_decision_tree = model_decision_tree.predict(X_test)\n",
    "\n",
    "sns.regplot(y_test[0:100],y_pred_reg[0:100])\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#model_regression.coef\n",
    "mse1 = mean_squared_error(y_test,y_pred_reg)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "rmse1 = np.sqrt(mse1)\n",
    "print(rmse1)\n",
    "\n",
    "mse2 = mean_squared_error(y_test,y_pred_random_forset)\n",
    "# we want smaller rmse\n",
    "rmse2 = np.sqrt(mse2)\n",
    "print(rmse2)\n",
    "\n",
    "mse3 = mean_squared_error(y_test,y_pred_decision_tree)\n",
    "# we want smaller rmse\n",
    "rmse3 = np.sqrt(mse3)\n",
    "print(rmse3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test_samples = 10\n",
    "regression = []\n",
    "random_forest = []\n",
    "decision_tree = []\n",
    "ground_truth = []\n",
    "for i in range(test_samples): \n",
    "    regression.append(model_regression.predict([X_test[i]])) \n",
    "    random_forest.append(model_random_forest.predict([X_test[i]]))\n",
    "    decision_tree.append(model_decision_tree.predict([X_test[i]]))\n",
    "    ground_truth.append(y_test[i])\n",
    "\n",
    "plt.plot(range(len(regression)), regression, label='Linear Regression')\n",
    "plt.plot(range(len(random_forest)), random_forest, label='Random Forest')\n",
    "plt.plot(range(len(decision_tree)), decision_tree, label='Decision Tree')\n",
    "plt.plot(range(len(ground_truth)), ground_truth, label='Ground Truth')\n",
    "plt.xlim([0, test_samples])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('songs')\n",
    "plt.ylabel('popularity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables normalization\n",
    "acousticness = [0,1]\n",
    "danceability = [0,1]\n",
    "duration_s = [0,600]\n",
    "energy = [0,1]\n",
    "instrumentalness = [0,1]\n",
    "liveness = [0,1]\n",
    "loudness= [ -60,0]\n",
    "speechiness = [0,1]\n",
    "tempo = [0,250]\n",
    "valence = [0,1]\n",
    "mode = [0,1]\n",
    "features_range = {\"acousticness\":[0,1],\"danceability\" : [0,1],\"duration_s\":[0,600],\"energy\":[0,1],\"instrumentalness\":[0,1],\"liveness\":[0,1],\"loudness\": [-60,0],\"speechiness\" : [0,1],\"tempo\" : [0,250],\"valence\" : [0,1],\"mode\" : [0,1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = [50]\n",
    "random_forest = [50]\n",
    "decision_tree = [50]\n",
    "features = X.shape[1]\n",
    "widgets_box = []\n",
    "headers = X.columns\n",
    "temp_sample =X.iloc[5]\n",
    "\n",
    "#features_range[\"acousticness\"][0]\n",
    "for feature in range(features):\n",
    "    \n",
    "    temp_widget = widgets.FloatSlider(\n",
    "    value=temp_sample[feature],\n",
    "    min=features_range[headers[feature]][0],\n",
    "    max=features_range[headers[feature]][1],\n",
    "    step=0.1,\n",
    "    description=headers[feature],\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='vertical',\n",
    "    readout=True,\n",
    "    readout_format='.1f',\n",
    "    )\n",
    "    widgets_box.append(temp_widget)\n",
    "\n",
    "\n",
    "box = Box(children=widgets_box)\n",
    "box "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in range(features): \n",
    "    temp_sample[feature] = widgets_box[feature].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regression.append(model_regression.predict([temp_sample])) \n",
    "random_forest.append(model_random_forest.predict([temp_sample]))\n",
    "decision_tree.append(model_decision_tree.predict([temp_sample]))\n",
    "\n",
    "# Plot a simple line chart\n",
    "plt.plot(range(len(regression)), regression, label='Linear Regression')\n",
    "plt.plot(range(len(random_forest)), random_forest, label='Random Forest')\n",
    "plt.plot(range(len(decision_tree)), decision_tree, label='Decision Tree')\n",
    "plt.xlim([0, len(regression)])\n",
    "plt.ylim([0, 100])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device =='cuda':\n",
    "    print(torch.cuda.get_device_name(device=device)) # check what kind of cpu/gpu we have\n",
    "# deep learning - create tensors\n",
    "X_tensor = torch.tensor(X.values,dtype=torch.float, device = device)\n",
    "y_tensor = torch.tensor(y.values,dtype=torch.float)\n",
    "\n",
    "# build Neural Networks - 18 input features, 100 hiden layers\n",
    "model = nn.Sequential(nn.Linear(X.shape[1],100),nn.ReLU(),nn.Linear(100,1))\n",
    "model.to(device)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Train the Nueral Network\n",
    "# Mean square error\n",
    "criterion = torch.nn.MSELoss() \n",
    "# Training the model using SGD approach \n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.9)\n",
    "\n",
    "#Training\n",
    "n_iters = X.shape[1]\n",
    "for epoch in range(n_iters):\n",
    "    total_loss = 0\n",
    "    for i in range(len(X_tensor)):\n",
    "        y_pred = model(X_tensor[i]) # single forward pass\n",
    "        loss = criterion(y_pred,y_tensor[i]) # estimating the model's prediction\n",
    "        total_loss += loss.item() \n",
    "\n",
    "        #weights update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Total loss: \", total_loss)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphPreditions(model,y_tensor,y_pred,0,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation=tf.nn.relu,input_shape=[X.shape[1]]),\n",
    "        layers.Dense(64, activation = tf.nn.relu),\n",
    "        layers.Dense(1)\n",
    "\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.RMSprop(.001)\n",
    "    model.compile(loss=\"mse\",optimizer=optimizer,metrics=['mae','mse']) # examine our model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs):\n",
    "        if epoch % 100==0: print(\"\")\n",
    "        print('.',end=\"\")\n",
    "\n",
    "EPOCHS = 100\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',patience=10)\n",
    "history = model.fit(\n",
    "    X,y, epochs = EPOCHS,validation_split = 0.2, verbose = 0,callbacks = [PrintDot()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error')\n",
    "    plt.plot(hist['epoch'], hist['mae'],label='Train Error')\n",
    "    plt.plot(hist['epoch'],hist['val_mae'],label='Validation Error')\n",
    "    plt.legend()\n",
    "    plt.ylim([0,1])\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error')\n",
    "    plt.plot(hist['epoch'], hist['mse'],label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mse'],label='Validation Error')\n",
    "    plt.legend()\n",
    "    plt.ylim([0,1])\n",
    "plot_history(history)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae, mse = model.evaluate(X_test,y_test,verbose=0)\n",
    "rmse_DL =  np.sqrt(mse)\n",
    "print(rmse_DL)\n",
    "test_predictions = model.predict(X_test).flatten()\n",
    "plt.scatter(y_test, test_predictions)\n",
    "plt.xlabel(\"True Value\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.axis('equal')\n",
    "plt.axis('Square')\n",
    "plt.xlim([0,plt.xlim()[1]])\n",
    "plt.ylim([0,plt.ylim()[1]])\n",
    "_ = plt.plot([-100,100],[-100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models' Mean Squared Error\n",
    "dl = np.array([np.nan,np.nan,0.4])\n",
    "plt.plot(Phase, regression_mse, label='Linear Regression')\n",
    "plt.plot(Phase, decision_tree_mse, label='Random Forest')\n",
    "plt.plot(Phase, random_forest_mse, label='Decision Tree')\n",
    "if version == 6:\n",
    "    plt.plot(Phase, dl, label='dl',linewidth=2,marker=\"*\")\n",
    "\n",
    "\n",
    "plt.xticks(Phase)\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f319479181283cf71dcef866b9dfb370990a8259534ff227f34530c4c05f245"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import ipywidgets as widgets # interactive widgets\n",
    "from ipywidgets import Box\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold\n",
    "# Deep learning\n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading and descriptive statistics\n",
    "df = pd.read_csv('SpotifyFeatures.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update column values\n",
    "df[\"genre\"].replace({\"Children's Music\": \"Children’s Music\"}, inplace=True)\n",
    "# general category\n",
    "df[\"genre\"].replace({\"Soundtrack\": \"General\",\"Movie\":\"General\",\"Anime\":\"General\",\"Children’s Music\":\"General\",\"Comedy\":\"General\"}, inplace=True)\n",
    "# dance\n",
    "df[\"genre\"].replace({\"Hip-Hop\": \"Dance\",\"R&B\":\"dance\",\"Dance\":\"Dance\",\"Rap\":\"Dance\",\"Pop\":\"Dance\"}, inplace=True)\n",
    "# folk\n",
    "df[\"genre\"].replace({\"Folk\": \"Folk\",\"Soul\":\"Folk\",\"Blues\":\"Folk\",\"Country\":\"Folk\"}, inplace=True)\n",
    "# Reggae\n",
    "df[\"genre\"].replace({\"Reggaeton\": \"Reggae\",\"Ska\":\"Reggae\",\"Reggae\":\"Reggae\",\"World\":\"Reggae\"}, inplace=True)\n",
    "# Alternative\n",
    "df[\"genre\"].replace({\"Indie\": \"Alternative\",\"Rock\":\"Alternative\",\"Alternative\":\"Alternative\",\"Electronic\":\"Alternative\",\"Jazz\":\"Alternative\"}, inplace=True)\n",
    "# Reggae\n",
    "df[\"genre\"].replace({\"Classical\": \"Classical\",\"Opera\":\"Classical\",\"A Capella\":\"Classical\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove duplicates + unnecessary variables\n",
    "df.drop_duplicates(subset=['track_id'], keep='first',inplace=True)\n",
    "df.drop(['artist_name','track_name','track_id','key'],axis=1, inplace=True)\n",
    "\n",
    "# Add dummy variables - time_signature\n",
    "time_signature_df=pd.get_dummies(df[\"time_signature\"]) \n",
    "df = pd.concat([df,time_signature_df],axis=1) \n",
    "\n",
    "# Add dummy variables - genre\n",
    "genre_df=pd.get_dummies(df[\"genre\"]) \n",
    "df = pd.concat([df,genre_df],axis=1) \n",
    "\n",
    "# remove old variables\n",
    "df.drop(['genre','time_signature','0/4','1/4'],axis=1, inplace=True)\n",
    "#df\n",
    "\n",
    "# Data cleaning and arrangement the data\n",
    "df['mode'] = np.where(df['mode']=='Major', 1, 0) #change songs' mode (minor/major) to numerical\n",
    "\n",
    "# change songs duration from milliseconds to seconds\n",
    "df['duration_ms'] = df['duration_ms'] / 1000\n",
    "df.rename(columns={'duration_ms': 'duration_s'}, inplace=True) # update column label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data standardtization\n",
    "features = [\"duration_s\",\"loudness\",\"tempo\",\"popularity\"]\n",
    "for feature in features:\n",
    "    mean = df[feature].mean()\n",
    "    std = df[feature].std()\n",
    "    df[feature] = (df[feature]-mean)/std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.loc[:,df.columns !=\"popularity\"]\n",
    "y = df[\"popularity\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualzation\n",
    "#sample = df.sample(1000)\n",
    "#sns.kdeplot(x = sample[\"acousticness\"])\n",
    "#sns.scatterplot(x=sample[\"acousticness\"], y=sample[\"popularity\"])\n",
    "#sns.pairplot(sample[[\"acousticness\",\"danceability\"]])\n",
    "#correlation_mat = df.corr()\n",
    "#print(correlation_mat)\n",
    "#sns.heatmap(correlation_mat)\n",
    "#sns.scatterplot(sample[\"loudness\"], sample[\"acousticness\"], hue=sample[\"popularity\"])\n",
    "#sns.scatterplot(sample[\"acousticness\"], sample[\"danceability\"], size=sample[\"popularity\"])\n",
    "#g = sns.PairGrid(sample[[ \"acousticness\",\"popularity\",\"genre\"]], hue=\"genre\")\n",
    "#g.map_diag(sns.histplot)\n",
    "#g.map_offdiag(sns.scatterplot)\n",
    "#g.add_legend();\n",
    "\n",
    "#df sample = diamonds.sample(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(sample[[\"loudness\", \"acousticness\", \"popularity\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test, and train multiple models by sampling the train set. Finally, just test once on the test set.\n",
    "# KFold with 5 splits \n",
    "folds = KFold(n_splits = 10, shuffle = True)\n",
    "\n",
    "hyper_params = [{'n_features_to_select': list(range(0, 18))}] # specify range of hyperparameters\n",
    "model_regression.fit(X_train,y_train)\n",
    "rfe = RFE(model_regression) \n",
    "model_cv = GridSearchCV(estimator = rfe, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'r2', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results \n",
    "y_pred_reg = model_cv.predict(X_test)\n",
    "#model_regression.coef\n",
    "mse1 = mean_squared_error(y_test,y_pred_reg)\n",
    "# we want smaller rmse\n",
    "rmse1 = np.sqrt(mse1)\n",
    "print(rmse1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_test_score\"])\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_train_score\"])\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('r-squared')\n",
    "plt.title(\"Optimal Number of Features\")\n",
    "plt.legend(['test score', 'train score'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the data to training and testing\n",
    "X_train, X_test, y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "# save as np.array\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train) \n",
    "y_test = np.array(y_test) \n",
    "\n",
    "#Split into train and test, and train multiple models by sampling the train set. Finally, just test once on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a linear regression object\n",
    "model_regression = linear_model.LinearRegression()\n",
    "\n",
    "# create a random forest regression object\n",
    "model_random_forest = RandomForestRegressor()\n",
    "\n",
    "# create a random forest regression object\n",
    "model_decision_tree = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The models\n",
    "model_regression.fit(X_train,y_train)\n",
    "model_random_forest.fit(X_train,y_train)\n",
    "model_decision_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf = model_random_forest(n_estimators = 300)\n",
    "\n",
    "\n",
    "# create a random forest regression object\n",
    "model_random_forest = RandomForestRegressor(n_estimators = 200)\n",
    "\n",
    "\n",
    "model_random_forest.fit(X_train,y_train)\n",
    "# estimate the R² score on train data\n",
    "print(\"Train data - the R^2 is\",model_random_forest.score(X_train,y_train))\n",
    "# estimate the R² score on test data\n",
    "print(\"Test data - the R^2 is\",model_random_forest.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hyper_params = [{'n_features_to_select': list(range(0, 18))}] # specify range of hyperparameters\n",
    "model_regression.fit(X_train,y_train)\n",
    "rfe = RFE(model_regression) \n",
    "model_cv = GridSearchCV(estimator = rfe, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'r2', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " y_pred_decision_tree= model_cv.predict(X_test)\n",
    "#model_regression.coef\n",
    "mse1 = mean_squared_error(y_test,y_pred_decision_tree)\n",
    "# we want smaller rmse\n",
    "rmse1 = np.sqrt(mse1)\n",
    "print(rmse1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the R² score on train data\n",
    "print(\"Train data - the R^2 is\",model_regression.score(X_train,y_train))\n",
    "# estimate the R² score on test data\n",
    "print(\"Test data - the R^2 is\",model_regression.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the R² score on train data\n",
    "print(\"Train data - the R^2 is\",model_random_forest.score(X_train,y_train))\n",
    "# estimate the R² score on test data\n",
    "print(\"Test data - the R^2 is\",model_random_forest.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the R² score on train data\n",
    "print(\"Train data - the R^2 is\",model_decision_tree.score(X_train,y_train))\n",
    "# estimate the R² score on test data\n",
    "print(\"Test data - the R^2 is\",model_decision_tree.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg = model_regression.predict(X_test)\n",
    "y_pred_random_forset = model_random_forest.predict(X_test)\n",
    "y_pred_decision_tree = model_decision_tree.predict(X_test)\n",
    "\n",
    "sns.regplot(y_test,y_pred_reg)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#model_regression.coef\n",
    "mse1 = mean_squared_error(y_test,y_pred_reg)\n",
    "# we want smaller rmse\n",
    "rmse1 = np.sqrt(mse1)\n",
    "print(rmse1)\n",
    "\n",
    "mse2 = mean_squared_error(y_test,y_pred_random_forset)\n",
    "# we want smaller rmse\n",
    "rmse2 = np.sqrt(mse2)\n",
    "print(rmse2)\n",
    "\n",
    "mse3 = mean_squared_error(y_test,y_pred_decision_tree)\n",
    "# we want smaller rmse\n",
    "rmse3 = np.sqrt(mse3)\n",
    "print(rmse3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test_samples = 10\n",
    "regression = []\n",
    "random_forest = []\n",
    "decision_tree = []\n",
    "ground_truth = []\n",
    "for i in range(test_samples): \n",
    "    regression.append(model_regression.predict([X_test[i]])) \n",
    "    random_forest.append(model_random_forest.predict([X_test[i]]))\n",
    "    decision_tree.append(model_decision_tree.predict([X_test[i]]))\n",
    "    ground_truth.append(y_test[i])\n",
    "\n",
    "plt.plot(range(len(regression)), regression, label='Linear Regression')\n",
    "plt.plot(range(len(random_forest)), random_forest, label='Random Forest')\n",
    "plt.plot(range(len(decision_tree)), decision_tree, label='Decision Tree')\n",
    "plt.plot(range(len(ground_truth)), ground_truth, label='Ground Truth')\n",
    "plt.xlim([0, test_samples])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('songs')\n",
    "plt.ylabel('popularity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables normalization\n",
    "acousticness = [0,1]\n",
    "danceability = [0,1]\n",
    "duration_s = [0,600]\n",
    "energy = [0,1]\n",
    "instrumentalness = [0,1]\n",
    "liveness = [0,1]\n",
    "loudness= [ -60,0]\n",
    "speechiness = [0,1]\n",
    "tempo = [0,250]\n",
    "valence = [0,1]\n",
    "mode = [0,1]\n",
    "features_range = {\"acousticness\":[0,1],\"danceability\" : [0,1],\"duration_s\":[0,600],\"energy\":[0,1],\"instrumentalness\":[0,1],\"liveness\":[0,1],\"loudness\": [-60,0],\"speechiness\" : [0,1],\"tempo\" : [0,250],\"valence\" : [0,1],\"mode\" : [0,1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = [50]\n",
    "random_forest = [50]\n",
    "decision_tree = [50]\n",
    "features = X.shape[1]\n",
    "widgets_box = []\n",
    "headers = X.columns\n",
    "temp_sample =X.iloc[5]\n",
    "\n",
    "#features_range[\"acousticness\"][0]\n",
    "for feature in range(features):\n",
    "    \n",
    "    temp_widget = widgets.FloatSlider(\n",
    "    value=temp_sample[feature],\n",
    "    min=features_range[headers[feature]][0],\n",
    "    max=features_range[headers[feature]][1],\n",
    "    step=0.1,\n",
    "    description=headers[feature],\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='vertical',\n",
    "    readout=True,\n",
    "    readout_format='.1f',\n",
    "    )\n",
    "    widgets_box.append(temp_widget)\n",
    "\n",
    "\n",
    "box = Box(children=widgets_box)\n",
    "box "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in range(features): \n",
    "    temp_sample[feature] = widgets_box[feature].value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regression.append(model_regression.predict([temp_sample])) \n",
    "random_forest.append(model_random_forest.predict([temp_sample]))\n",
    "decision_tree.append(model_decision_tree.predict([temp_sample]))\n",
    "\n",
    "# Plot a simple line chart\n",
    "plt.plot(range(len(regression)), regression, label='Linear Regression')\n",
    "plt.plot(range(len(random_forest)), random_forest, label='Random Forest')\n",
    "plt.plot(range(len(decision_tree)), decision_tree, label='Decision Tree')\n",
    "plt.xlim([0, len(regression)])\n",
    "plt.ylim([0, 100])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f319479181283cf71dcef866b9dfb370990a8259534ff227f34530c4c05f245"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

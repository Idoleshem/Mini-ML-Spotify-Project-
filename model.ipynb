{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dd0c28c738f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ido Leshem\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ido Leshem\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m from .utils._tags import (\n\u001b[0;32m     19\u001b[0m     \u001b[0m_DEFAULT_TAGS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ido Leshem\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m from .validation import (\n",
      "\u001b[1;32mc:\\Users\\Ido Leshem\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlsqr\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msparse_lsqr\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mthreadpoolctl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\scipy\\stats\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    439\u001b[0m \"\"\"\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\scipy\\stats\\distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#       instead of `git blame -Lxxx,+x`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_distn_infrastructure\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrv_discrete\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrv_continuous\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrv_frozen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_continuous_distns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\scipy\\stats\\_distn_infrastructure.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# for root finding for continuous distribution ppf, and max likelihood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# estimation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\scipy\\optimize\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_minimize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_root_scalar\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlbfgsb\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_minimize_lbfgsb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtnc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_minimize_tnc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcobyla\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_minimize_cobyla\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mslsqp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_minimize_slsqp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m from ._constraints import (old_bound_to_new, new_bounds_to_old,\n",
      "\u001b[1;32mc:\\Users\\Ido Leshem\\AppData\\Local\\Programs\\Python\\Python38\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ido Leshem\\AppData\\Local\\Programs\\Python\\Python38\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ido Leshem\\AppData\\Local\\Programs\\Python\\Python38\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ido Leshem\\AppData\\Local\\Programs\\Python\\Python38\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ido Leshem\\AppData\\Local\\Programs\\Python\\Python38\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ido Leshem\\AppData\\Local\\Programs\\Python\\Python38\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import ipywidgets as widgets # interactive widgets\n",
    "from ipywidgets import Box\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#version = 1 # no genre and time signature values\n",
    "#version = 2 # with new variables \n",
    "#version = 3 # data standartization \n",
    "#version = 4 # Feature Selection\n",
    "version = 5 # Cross Validation GridSearchCV\n",
    "#version = 6 # Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading and descriptive statistics\n",
    "df = pd.read_csv('SpotifyFeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update column values\n",
    "df[\"genre\"].replace({\"Children's Music\": \"Children’s Music\"}, inplace=True)\n",
    "# general category\n",
    "df[\"genre\"].replace({\"Soundtrack\": \"General\",\"Movie\":\"General\",\"Anime\":\"General\",\"Children’s Music\":\"General\",\"Comedy\":\"General\"}, inplace=True)\n",
    "# dance\n",
    "df[\"genre\"].replace({\"Hip-Hop\": \"Dance\",\"R&B\":\"dance\",\"Dance\":\"Dance\",\"Rap\":\"Dance\",\"Pop\":\"Dance\"}, inplace=True)\n",
    "# folk\n",
    "df[\"genre\"].replace({\"Folk\": \"Folk\",\"Soul\":\"Folk\",\"Blues\":\"Folk\",\"Country\":\"Folk\"}, inplace=True)\n",
    "# Reggae\n",
    "df[\"genre\"].replace({\"Reggaeton\": \"Reggae\",\"Ska\":\"Reggae\",\"Reggae\":\"Reggae\",\"World\":\"Reggae\"}, inplace=True)\n",
    "# Alternative\n",
    "df[\"genre\"].replace({\"Indie\": \"Alternative\",\"Rock\":\"Alternative\",\"Alternative\":\"Alternative\",\"Electronic\":\"Alternative\",\"Jazz\":\"Alternative\"}, inplace=True)\n",
    "# Reggae\n",
    "df[\"genre\"].replace({\"Classical\": \"Classical\",\"Opera\":\"Classical\",\"A Capella\":\"Classical\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for version +2\n",
    "# create dummy variables\n",
    "if version>=2:\n",
    "    genre_df=pd.get_dummies(df[\"genre\"]) \n",
    "    df = pd.concat([df,genre_df],axis=1) \n",
    "\n",
    "    # create dummy variables - time_signature\n",
    "    time_signature_df=pd.get_dummies(df[\"time_signature\"]) \n",
    "    df = pd.concat([df,time_signature_df],axis=1) \n",
    "\n",
    "    # remove old variables\n",
    "    df.drop(['genre','time_signature','0/4','1/4'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all versions\n",
    "# Data cleaning and arrangement the data\n",
    "df['mode'] = np.where(df['mode']=='Major', 1, 0) #change songs' mode (minor/major) to numerical\n",
    "\n",
    "# change songs duration from milliseconds to seconds\n",
    "df['duration_ms'] = df['duration_ms'] / 1000\n",
    "df.rename(columns={'duration_ms': 'duration_s'}, inplace=True) # update column label\n",
    "\n",
    "# drop variables:\n",
    "df.drop_duplicates(subset=['track_id'], keep='first',inplace=True)\n",
    "if version==1:\n",
    "    df.drop(['artist_name','track_name','track_id','key','genre','time_signature'],axis=1, inplace=True)\n",
    "\n",
    "elif version>=2:\n",
    "    df.drop(['artist_name','track_name','track_id','key'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# versions +3\n",
    "# data standardtization\n",
    "# scale the dataset and make computations more efficient\n",
    "if version ==3:\n",
    "    features = [\"duration_s\",\"loudness\",\"tempo\",\"popularity\"]\n",
    "    for feature in features:\n",
    "        mean = df[feature].mean()\n",
    "        std = df[feature].std()\n",
    "        df[feature] = (df[feature]-mean)/std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection - version +4\n",
    "if version ==4:\n",
    "    df.drop(['duration_s','mode','tempo','valence','5/4','Reggae'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All versions\n",
    "X= df.loc[:,df.columns !=\"popularity\"]\n",
    "y = df[\"popularity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualzation\n",
    "#sample = df.sample(1000)\n",
    "#sns.kdeplot(x = sample[\"acousticness\"])\n",
    "#sns.scatterplot(x=sample[\"acousticness\"], y=sample[\"popularity\"])\n",
    "#sns.pairplot(sample[[\"acousticness\",\"danceability\"]])\n",
    "#correlation_mat = df.corr()\n",
    "#print(correlation_mat)\n",
    "#sns.heatmap(correlation_mat)\n",
    "#sns.scatterplot(sample[\"loudness\"], sample[\"acousticness\"], hue=sample[\"popularity\"])\n",
    "#sns.scatterplot(sample[\"acousticness\"], sample[\"danceability\"], size=sample[\"popularity\"])\n",
    "#g = sns.PairGrid(sample[[ \"acousticness\",\"popularity\",\"genre\"]], hue=\"genre\")\n",
    "#g.map_diag(sns.histplot)\n",
    "#g.map_offdiag(sns.scatterplot)\n",
    "#g.add_legend();\n",
    "\n",
    "#df sample = diamonds.sample(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 3\n",
    "if version ==3:\n",
    "    correlation_mat = df.corr()\n",
    "    print(correlation_mat)\n",
    "#sns.heatmap(correlation_mat,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 4\n",
    "if version ==4:\n",
    "    sample = df.sample(500)\n",
    "    #g = sns.pairplot(sample[[\"loudness\", \"acousticness\", \"popularity\"]])\n",
    "    sns.pairplot(sample[[\"danceability\",\"loudness\", \"acousticness\", \"popularity\"]],diag_kind=\"kde\")\n",
    "    sns.pairplot(sample[[\"danceability\",\"loudness\", \"acousticness\", \"popularity\",\"genre\"]], hue=\"genre\")\n",
    "\"\"\"\n",
    "sns.pairplot(sample[[\"danceability\",\"loudness\", \"acousticness\", \"popularity\"]],diag_kind=\"kde\")\n",
    "\n",
    "acousticness = [0,1]\n",
    "danceability = [0,1]\n",
    "duration_s = [0,600]\n",
    "energy = [0,1]\n",
    "instrumentalness = [0,1]\n",
    "liveness = [0,1]\n",
    "loudness= [ -60,0]\n",
    "speechiness = [0,1]\n",
    "tempo = [0,250]\n",
    "valence = [0,1]\n",
    "mode = [0,1]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a linear regression object\n",
    "model_regression = linear_model.LinearRegression()\n",
    "\n",
    "# create a random forest regression object\n",
    "model_random_forest = RandomForestRegressor()\n",
    "\n",
    "# create a random forest regression object\n",
    "model_decision_tree = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only on the first time\n",
    "# MSE Track\n",
    "if version == 1:\n",
    "    regression_rmse = []\n",
    "    random_forest_rmse = []\n",
    "    decision_tree_rmse = []\n",
    "\n",
    "    Phase = ['baseline','feature engineering','data standartization','feature selection','cross validation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the data to training and testing\n",
    "X_train, X_test, y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "# save as np.array\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train) \n",
    "y_test = np.array(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 5\n",
    "\"\"\"\n",
    "if version ==5:\n",
    "    folds = KFold(n_splits = 10, shuffle = True)\n",
    "    hyper_params = [{'n_features_to_select': list(range(0,X.shape[1]))}] # specify range of hyperparameters\n",
    "    model_regression.fit(X_train,y_train)\n",
    "    rfe = RFE(model_regression) \n",
    "    model_cv = GridSearchCV(estimator = rfe, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'r2', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)    \n",
    "\n",
    "    # fit the model\n",
    "    model_cv.fit(X_train, y_train)\n",
    "    cv_results = pd.DataFrame(model_cv.cv_results_) \n",
    "    y_pred = model_cv.predict(X_test)\n",
    "    #model_regression.coef\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The models\n",
    "if version ==5:    \n",
    "    model_random_forest.fit(X_train,y_train)\n",
    "    model_decision_tree.fit(X_train,y_train)\n",
    "else:\n",
    "    model_regression.fit(X_train,y_train)\n",
    "    model_random_forest.fit(X_train,y_train)\n",
    "    model_decision_tree.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 5\n",
    "if version == 5:\n",
    "    hyper_params = [{'n_features_to_select': list(range(0, 18))}] # specify range of hyperparameters\n",
    "    rfe = RFE(model_regression) \n",
    "    model_model_regression_cv = GridSearchCV(estimator = rfe, \n",
    "                            param_grid = hyper_params, \n",
    "                            scoring= 'r2', \n",
    "                            cv = folds, \n",
    "                            verbose = 1,\n",
    "                            return_train_score=True)      \n",
    "\n",
    "    # fit the model\n",
    "    model_model_regression_cv.fit(X_train, y_train)\n",
    "\n",
    "    cv_results = pd.DataFrame(model_model_regression_cv.cv_results_)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 5 \n",
    "if version == 5:\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_test_score\"])\n",
    "    plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_train_score\"])\n",
    "    plt.xlabel('number of features')\n",
    "    plt.ylabel('r-squared')\n",
    "    plt.title(\"Optimal Number of Features\")\n",
    "    plt.legend(['test score', 'train score'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not relevant\n",
    "\"\"\"\n",
    "# estimate the R² score on train data\n",
    "print(\"Train data - the R^2 is\",model_regression.score(X_train,y_train))\n",
    "# estimate the R² score on test data\n",
    "print(\"Test data - the R^2 is\",model_regression.score(X_test,y_test))\n",
    "\n",
    "# not relevant\n",
    "# estimate the R² score on train data\n",
    "print(\"Train data - the R^2 is\",model_random_forest.score(X_train,y_train))\n",
    "# estimate the R² score on test data\n",
    "print(\"Test data - the R^2 is\",model_random_forest.score(X_test,y_test))\n",
    "\n",
    "# not relevant\n",
    "# estimate the R² score on train data\n",
    "print(\"Train data - the R^2 is\",model_decision_tree.score(X_train,y_train))\n",
    "# estimate the R² score on test data\n",
    "print(\"Test data - the R^2 is\",model_decision_tree.score(X_test,y_test))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all versions\n",
    "if version != 5:\n",
    "    y_pred_reg = model_regression.predict(X_test)\n",
    "if version == 5:\n",
    "    y_pred_reg = model_model_regression_cv.predict(X_test)\n",
    "y_pred_random_forset = model_random_forest.predict(X_test)\n",
    "y_pred_decision_tree = model_decision_tree.predict(X_test)\n",
    "\n",
    "#sns.regplot(y_test[0:100],y_pred_reg[0:100])\n",
    "mse1 = mean_squared_error(y_test,y_pred_reg)\n",
    "\n",
    "rmse1 = np.sqrt(mse1)\n",
    "\n",
    "mse2 = mean_squared_error(y_test,y_pred_random_forset)\n",
    "# we want smaller rmse\n",
    "rmse2 = np.sqrt(mse2)\n",
    "\n",
    "\n",
    "mse3 = mean_squared_error(y_test,y_pred_decision_tree)\n",
    "# we want smaller rmse\n",
    "rmse3 = np.sqrt(mse3)\n",
    "\n",
    "\n",
    "regression_rmse.append(rmse1)\n",
    "random_forest_rmse.append(rmse2)\n",
    "decision_tree_rmse.append(rmse3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "test_samples = 10\n",
    "regression = []\n",
    "random_forest = []\n",
    "decision_tree = []\n",
    "ground_truth = []\n",
    "for i in range(test_samples): \n",
    "    regression.append(model_regression.predict([X_test[i]])) \n",
    "    random_forest.append(model_random_forest.predict([X_test[i]]))\n",
    "    decision_tree.append(model_decision_tree.predict([X_test[i]]))\n",
    "    ground_truth.append(y_test[i])\n",
    "\n",
    "plt.plot(range(len(regression)), regression, label='Linear Regression')\n",
    "plt.plot(range(len(random_forest)), random_forest, label='Random Forest')\n",
    "plt.plot(range(len(decision_tree)), decision_tree, label='Decision Tree')\n",
    "plt.plot(range(len(ground_truth)), ground_truth, label='Ground Truth')\n",
    "plt.xlim([0, test_samples])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('songs')\n",
    "plt.ylabel('popularity')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Variables normalization\n",
    "acousticness = [0,1]\n",
    "danceability = [0,1]\n",
    "duration_s = [0,600]\n",
    "energy = [0,1]\n",
    "instrumentalness = [0,1]\n",
    "liveness = [0,1]\n",
    "loudness= [ -60,0]\n",
    "speechiness = [0,1]\n",
    "tempo = [0,250]\n",
    "valence = [0,1]\n",
    "mode = [0,1]\n",
    "features_range = {\"acousticness\":[0,1],\"danceability\" : [0,1],\"duration_s\":[0,600],\"energy\":[0,1],\"instrumentalness\":[0,1],\"liveness\":[0,1],\"loudness\": [-60,0],\"speechiness\" : [0,1],\"tempo\" : [0,250],\"valence\" : [0,1],\"mode\" : [0,1]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "regression = [50]\n",
    "random_forest = [50]\n",
    "decision_tree = [50]\n",
    "features = X.shape[1]\n",
    "widgets_box = []\n",
    "headers = X.columns\n",
    "temp_sample =X.iloc[5]\n",
    "\n",
    "#features_range[\"acousticness\"][0]\n",
    "for feature in range(features):\n",
    "    \n",
    "    temp_widget = widgets.FloatSlider(\n",
    "    value=temp_sample[feature],\n",
    "    min=features_range[headers[feature]][0],\n",
    "    max=features_range[headers[feature]][1],\n",
    "    step=0.1,\n",
    "    description=headers[feature],\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='vertical',\n",
    "    readout=True,\n",
    "    readout_format='.1f',\n",
    "    )\n",
    "    widgets_box.append(temp_widget)\n",
    "\n",
    "\n",
    "box = Box(children=widgets_box)\n",
    "box \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for feature in range(features): \n",
    "    temp_sample[feature] = widgets_box[feature].value\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "regression.append(model_regression.predict([temp_sample])) \n",
    "random_forest.append(model_random_forest.predict([temp_sample]))\n",
    "decision_tree.append(model_decision_tree.predict([temp_sample]))\n",
    "\n",
    "# Plot a simple line chart\n",
    "plt.plot(range(len(regression)), regression, label='Linear Regression')\n",
    "plt.plot(range(len(random_forest)), random_forest, label='Random Forest')\n",
    "plt.plot(range(len(decision_tree)), decision_tree, label='Decision Tree')\n",
    "plt.xlim([0, len(regression)])\n",
    "plt.ylim([0, 100])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation=tf.nn.relu,input_shape=[X.shape[1]]),\n",
    "        layers.Dense(64, activation = tf.nn.relu),\n",
    "        layers.Dense(1)\n",
    "\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.RMSprop(.001)\n",
    "    model.compile(loss=\"mse\",optimizer=optimizer,metrics=['mae','mse']) # examine our model\n",
    "    return model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if version ==6:\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if version == 6:\n",
    "    # train the model\n",
    "    class PrintDot(keras.callbacks.Callback):\n",
    "        def on_epoch_end(self,epoch,logs):\n",
    "            if epoch % 100==0: print(\"\")\n",
    "            print('.',end=\"\")\n",
    "\n",
    "    EPOCHS = 500\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',patience=10)\n",
    "    history = model.fit(\n",
    "        X,y, epochs = EPOCHS,validation_split = 0.2, verbose = 0,callbacks = [PrintDot()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if version == 6:\n",
    "    def plot_history(history):\n",
    "        hist = pd.DataFrame(history.history)\n",
    "        hist['epoch'] = history.epoch\n",
    "        plt.figure()\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Mean Abs Error')\n",
    "        plt.plot(hist['epoch'], hist['mae'],label='Train Error')\n",
    "        plt.plot(hist['epoch'],hist['val_mae'],label='Validation Error')\n",
    "        plt.legend()\n",
    "        plt.ylim([0,1])\n",
    "        plt.figure()\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Mean Square Error')\n",
    "        plt.plot(hist['epoch'], hist['mse'],label='Train Error')\n",
    "        plt.plot(hist['epoch'], hist['val_mse'],label='Validation Error')\n",
    "        plt.legend()\n",
    "        plt.ylim([0,1])\n",
    "    plot_history(history)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if version ==6:\n",
    "    loss, mae, mse = model.evaluate(X_test,y_test,verbose=0)\n",
    "    rmse_DL =  np.sqrt(mse)\n",
    "    dl = [np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "    dl.append(rmse_DL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_predictions = model.predict(X_test).flatten()\n",
    "plt.scatter(y_test[0:100], test_predictions[0:100])\n",
    "plt.xlabel(\"True Value\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.axis('equal')\n",
    "plt.axis('Square')\n",
    "plt.xlim([0,plt.xlim()[1]])\n",
    "plt.ylim([0,plt.ylim()[1]])\n",
    "_ = plt.plot([-100,100],[-100,100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models' Mean Squared Error\n",
    "\n",
    "\n",
    "plt.plot(Phase[0:len(regression_rmse)], regression_rmse, label='Linear Regression')\n",
    "plt.plot(Phase[0:len(regression_rmse)], decision_tree_rmse, label='Decision Tree')\n",
    "plt.plot(Phase[0:len(regression_rmse)], random_forest_rmse, label='Random Forest')\n",
    "#if version == 6:\n",
    "    #plt.plot(Phase, dl, label='dl',linewidth=2,marker=\"*\")\n",
    "plt.xticks(Phase[0:len(regression_rmse)])\n",
    "plt.ylim([0, 20])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(regression_rmse,decision_tree_rmse,random_forest_rmse)\n",
    "print(dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# not relevant\n",
    "# create a random forest regression object\n",
    "model_random_forest = RandomForestRegressor(n_estimators = 200)\n",
    "\n",
    "model_random_forest.fit(X_train,y_train)\n",
    "# estimate the R² score on train data\n",
    "print(\"Train data - the R^2 is\",model_random_forest.score(X_train,y_train))\n",
    "# estimate the R² score on test data\n",
    "print(\"Test data - the R^2 is\",model_random_forest.score(X_test,y_test))\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f319479181283cf71dcef866b9dfb370990a8259534ff227f34530c4c05f245"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
